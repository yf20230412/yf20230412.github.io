# -*- coding: utf-8 -*-
import requests
import re
import json
import traceback
import sys

sys.path.append('../../')
try:
    from base.spider import Spider
except ImportError:
    # å®šä¹‰ä¸€ä¸ªåŸºç¡€æ¥å£ç±»ï¼Œç”¨äºæœ¬åœ°æµ‹è¯•
    class Spider:
        def init(self, extend=""):
            pass

class Spider(Spider):
    def __init__(self):
        self.siteUrl = "https://www.kuaikaw.cn"
        self.nextData = None  # ç¼“å­˜NEXT_DATAæ•°æ®
        self.cateManual = {
            "ç”œå® ": "462",
            "å¤è£…ä»™ä¾ ": "1102",
            "ç°ä»£è¨€æƒ…": "1145",
            "é’æ˜¥": "1170",
            "è±ªé—¨æ©æ€¨": "585",
            "é€†è¢­": "417-464",
            "é‡ç”Ÿ": "439-465",
            "ç³»ç»Ÿ": "1159",
            "æ€»è£": "1147",
            "èŒåœºå•†æˆ˜": "943"
        }
        
    def getName(self):
        # è¿”å›çˆ¬è™«åç§°
        return "æ²³é©¬çŸ­å‰§"
    
    def init(self, extend=""):
        return
    
    def fetch(self, url, headers=None):
        """ç»Ÿä¸€çš„ç½‘ç»œè¯·æ±‚æ¥å£"""
        if headers is None:
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0",
                "Referer": self.siteUrl,
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
                "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8"
            }
        
        try:
            response = requests.get(url, headers=headers, timeout=10, allow_redirects=True)
            response.raise_for_status()
            return response
        except Exception as e:
            print(f"è¯·æ±‚å¼‚å¸¸: {url}, é”™è¯¯: {str(e)}")
            return None
    
    def isVideoFormat(self, url):
        # æ£€æŸ¥æ˜¯å¦ä¸ºè§†é¢‘æ ¼å¼
        video_formats = ['.mp4', '.mkv', '.avi', '.wmv', '.m3u8', '.flv', '.rmvb']
        for format in video_formats:
            if format in url.lower():
                return True
        return False
    
    def manualVideoCheck(self):
        # ä¸éœ€è¦æ‰‹åŠ¨æ£€æŸ¥
        return False
    
    def homeContent(self, filter):
        """è·å–é¦–é¡µåˆ†ç±»åŠç­›é€‰"""
        result = {}
        # åˆ†ç±»åˆ—è¡¨ï¼Œä½¿ç”¨å·²åˆå§‹åŒ–çš„cateManual
        classes = []
        for k in self.cateManual:
            classes.append({
                'type_name': k,
                'type_id': self.cateManual[k]
            })
        result['class'] = classes
        # è·å–é¦–é¡µæ¨èè§†é¢‘
        try:
            result['list'] = self.homeVideoContent()['list']
        except:
            result['list'] = []
  
        return result
    
    def homeVideoContent(self):
        """è·å–é¦–é¡µæ¨èè§†é¢‘å†…å®¹"""
        videos = []
        try:
            response = self.fetch(self.siteUrl)
            html_content = response.text
            # æå–NEXT_DATA JSONæ•°æ®
            next_data_pattern = r'<script id="__NEXT_DATA__" type="application/json">(.*?)</script>'
            next_data_match = re.search(next_data_pattern, html_content, re.DOTALL)
            if next_data_match:
                next_data_json = json.loads(next_data_match.group(1))
                page_props = next_data_json.get("props", {}).get("pageProps", {})
                # è·å–è½®æ’­å›¾æ•°æ® - è¿™äº›é€šå¸¸æ˜¯æ¨èå†…å®¹
                if "bannerList" in page_props and isinstance(page_props["bannerList"], list):
                    banner_list = page_props["bannerList"]
                    for banner in banner_list:
                        book_id = banner.get("bookId", "")
                        book_name = banner.get("bookName", "")
                        cover_url = banner.get("coverWap", banner.get("wapUrl", ""))
                        # è·å–çŠ¶æ€å’Œç« èŠ‚æ•°
                        status = banner.get("statusDesc", "")
                        total_chapters = banner.get("totalChapterNum", "")
                        if book_id and book_name:
                            videos.append({
                                "vod_id": f"/drama/{book_id}",
                                "vod_name": book_name,
                                "vod_pic": cover_url,
                                "vod_remarks": f"{status} {total_chapters}é›†" if total_chapters else status
                            })
                
                # SEOåˆ†ç±»ä¸‹çš„æ¨è
                if "seoColumnVos" in page_props and isinstance(page_props["seoColumnVos"], list):
                    for column in page_props["seoColumnVos"]:
                        book_infos = column.get("bookInfos", [])
                        for book in book_infos:
                            book_id = book.get("bookId", "")
                            book_name = book.get("bookName", "")
                            cover_url = book.get("coverWap", "")
                            status = book.get("statusDesc", "")
                            total_chapters = book.get("totalChapterNum", "")
                            
                            if book_id and book_name:
                                videos.append({
                                    "vod_id": f"/drama/{book_id}",
                                    "vod_name": book_name,
                                    "vod_pic": cover_url,
                                    "vod_remarks": f"{status} {total_chapters}é›†" if total_chapters else status
                                })
                 
            # # å»é‡
            # seen = set()
            # unique_videos = []
            # for video in videos:
            #     if video["vod_id"] not in seen:
            #         seen.add(video["vod_id"])
            #         unique_videos.append(video)
            # videos = unique_videos
        
        except Exception as e:
            print(f"è·å–é¦–é¡µæ¨èå†…å®¹å‡ºé”™: {e}")
        
        result = {
            "list": videos
        }
        return result
    
    def categoryContent(self, tid, pg, filter, extend):
        """è·å–åˆ†ç±»å†…å®¹"""
        result = {}
        videos = []
        url = f"{self.siteUrl}/browse/{tid}/{pg}"
        response = self.fetch(url)
        html_content = response.text
        # æå–NEXT_DATA JSONæ•°æ®
        next_data_pattern = r'<script id="__NEXT_DATA__" type="application/json">(.*?)</script>'
        next_data_match = re.search(next_data_pattern, html_content, re.DOTALL)
        if next_data_match:
            next_data_json = json.loads(next_data_match.group(1))
            page_props = next_data_json.get("props", {}).get("pageProps", {})
            # è·å–æ€»é¡µæ•°å’Œå½“å‰é¡µ
            current_page = page_props.get("page", 1)
            total_pages = page_props.get("pages", 1)
            # è·å–ä¹¦ç±åˆ—è¡¨
            book_list = page_props.get("bookList", [])
            # è½¬æ¢ä¸ºé€šç”¨æ ¼å¼
            for book in book_list:
                book_id = book.get("bookId", "")
                book_name = book.get("bookName", "")
                cover_url = book.get("coverWap", "")
                status_desc = book.get("statusDesc", "")
                total_chapters = book.get("totalChapterNum", "")
                if book_id and book_name:
                    videos.append({
                        "vod_id": f"/drama/{book_id}",
                        "vod_name": book_name,
                        "vod_pic": cover_url,
                        "vod_remarks": f"{status_desc} {total_chapters}é›†" if total_chapters else status_desc
                    })
            # æ„å»ºè¿”å›ç»“æœ
            result = {
                "list": videos,
                "page": int(current_page),
                "pagecount": total_pages,
                "limit": len(videos),
                "total": total_pages * len(videos) if videos else 0
            }
        return result
    
    def switch(self, key, pg):
        # æœç´¢åŠŸèƒ½
        search_results = []
        # è·å–ç¬¬ä¸€é¡µç»“æœï¼Œå¹¶æ£€æŸ¥æ€»é¡µæ•°
        url = f"{self.siteUrl}/search?searchValue={key}&page={pg}"
        response = self.fetch(url)
        html_content = response.text
        # æå–NEXT_DATA JSONæ•°æ®
        next_data_pattern = r'<script id="__NEXT_DATA__" type="application/json">(.*?)</script>'
        next_data_match = re.search(next_data_pattern, html_content, re.DOTALL)
        if next_data_match:
            next_data_json = json.loads(next_data_match.group(1))
            page_props = next_data_json.get("props", {}).get("pageProps", {})
            # è·å–æ€»é¡µæ•°
            total_pages = page_props.get("pages", 1)
            # å¤„ç†æ‰€æœ‰é¡µçš„æ•°æ®
            all_book_list = []
            # æ·»åŠ ç¬¬ä¸€é¡µçš„ä¹¦ç±åˆ—è¡¨
            book_list = page_props.get("bookList", [])
            all_book_list.extend(book_list)
            # å¦‚æœæœ‰å¤šé¡µï¼Œè·å–å…¶ä»–é¡µçš„æ•°æ®
            if total_pages > 1 :  # quickæ¨¡å¼åªè·å–ç¬¬ä¸€é¡µ
                for page in range(2, total_pages + 1):
                    next_page_url = f"{self.siteUrl}/search?searchValue={key}&page={page}"
                    next_page_response = self.fetch(next_page_url)
                    next_page_html = next_page_response.text
                    next_page_match = re.search(next_data_pattern, next_page_html, re.DOTALL)
                    if next_page_match:
                        next_page_json = json.loads(next_page_match.group(1))
                        next_page_props = next_page_json.get("props", {}).get("pageProps", {})
                        next_page_books = next_page_props.get("bookList", [])
                        all_book_list.extend(next_page_books)
            # è½¬æ¢ä¸ºç»Ÿä¸€çš„æœç´¢ç»“æœæ ¼å¼
            for book in all_book_list:
                book_id = book.get("bookId", "")
                book_name = book.get("bookName", "")
                cover_url = book.get("coverWap", "")
                total_chapters = book.get("totalChapterNum", "0")
                status_desc = book.get("statusDesc", "")
                # æ„å»ºè§†é¢‘é¡¹
                vod = {
                    "vod_id": f"/drama/{book_id}",
                    "vod_name": book_name,
                    "vod_pic": cover_url,
                    "vod_remarks": f"{status_desc} {total_chapters}é›†"
                }
                search_results.append(vod)
        result = {
            "list": search_results,
            "page": pg
        }
        return result

    def searchContent(self, key, quick, pg=1):
        result = self.switch(key, pg=pg)
        result['page'] = pg
        return result
    
    def searchContentPage(self, key, quick, pg=1):
        return self.searchContent(key, quick, pg)

    def detailContent(self, ids):
        # è·å–å‰§é›†ä¿¡æ¯
        vod_id = ids[0]
        episode_id = None
        chapter_id = None
        
        if not vod_id.startswith('/drama/'):
            if vod_id.startswith('/episode/'):
                episode_info = vod_id.replace('/episode/', '').split('/')
                if len(episode_info) >= 2:
                    episode_id = episode_info[0]
                    chapter_id = episode_info[1]
                    vod_id = f'/drama/{episode_id}'
            else:
                vod_id = '/drama/' + vod_id
        
        drama_url = self.siteUrl + vod_id
        print(f"è¯·æ±‚URL: {drama_url}")
        
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0",
            "Referer": self.siteUrl,
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
            "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8"
        }
        
        rsp = self.fetch(drama_url, headers=headers)
        if not rsp or rsp.status_code != 200:
            print(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {getattr(rsp, 'status_code', 'N/A')}")
            return {}
        
        html = rsp.text
        next_data_match = re.search(r'<script id="__NEXT_DATA__" type="application/json">(.*?)</script>', html, re.DOTALL)
        
        if not next_data_match:
            print("æœªæ‰¾åˆ°NEXT_DATAå†…å®¹")
            return {}
        
        try:
            next_data = json.loads(next_data_match.group(1))
            page_props = next_data.get("props", {}).get("pageProps", {})
            print(f"æ‰¾åˆ°é¡µé¢å±æ€§ï¼ŒåŒ…å« {len(page_props.keys())} ä¸ªé”®")
            
            book_info = page_props.get("bookInfoVo", {})
            chapter_list = page_props.get("chapterList", [])
            
            title = book_info.get("title", "")
            sub_title = f"{book_info.get('totalChapterNum', '')}é›†"
            
            categories = []
            for category in book_info.get("categoryList", []):
                categories.append(category.get("name", ""))
            
            vod_content = book_info.get("introduction", "")
            
            vod = {
                "vod_id": vod_id,
                "vod_name": title,
                "vod_pic": book_info.get("coverWap", ""),
                "type_name": ",".join(categories),
                "vod_year": "",
                "vod_area": book_info.get("countryName", ""),
                "vod_remarks": sub_title,
                "vod_actor": ", ".join([p.get("name", "") for p in book_info.get("performerList", [])]),
                "vod_director": "",
                "vod_content": vod_content
            }
            
            # å¤„ç†æ’­æ”¾åˆ—è¡¨
            play_url_list = []
            episodes = []
            
            if chapter_list:
                print(f"æ‰¾åˆ° {len(chapter_list)} ä¸ªç« èŠ‚")
                
                # å…ˆæ£€æŸ¥æ˜¯å¦æœ‰å¯ä»¥ç›´æ¥ä½¿ç”¨çš„MP4é“¾æ¥ä½œä¸ºæ¨¡æ¿
                mp4_template = None
                first_mp4_chapter_id = None
                
                # å…ˆæœç´¢ç¬¬ä¸€ä¸ªç« èŠ‚çš„MP4é“¾æ¥
                # ä¸ºæé«˜æˆåŠŸç‡ï¼Œå°è¯•ç›´æ¥è¯·æ±‚ç¬¬ä¸€ä¸ªç« èŠ‚çš„æ’­æ”¾é¡µ
                if chapter_list and len(chapter_list) > 0:
                    first_chapter = chapter_list[0]
                    first_chapter_id = first_chapter.get("chapterId", "")
                    drama_id_clean = vod_id.replace('/drama/', '')
                    
                    if first_chapter_id and drama_id_clean:
                        first_episode_url = f"{self.siteUrl}/episode/{drama_id_clean}/{first_chapter_id}"
                        print(f"è¯·æ±‚ç¬¬ä¸€é›†æ’­æ”¾é¡µ: {first_episode_url}")
                        
                        first_rsp = self.fetch(first_episode_url, headers=headers)
                        if first_rsp and first_rsp.status_code == 200:
                            first_html = first_rsp.text
                            # ç›´æ¥ä»HTMLæå–MP4é“¾æ¥
                            mp4_pattern = r'(https?://[^"\']+\.mp4)'
                            mp4_matches = re.findall(mp4_pattern, first_html)
                            if mp4_matches:
                                mp4_template = mp4_matches[0]
                                first_mp4_chapter_id = first_chapter_id
                                print(f"æ‰¾åˆ°MP4é“¾æ¥æ¨¡æ¿: {mp4_template}")
                                print(f"æ¨¡æ¿å¯¹åº”çš„ç« èŠ‚ID: {first_mp4_chapter_id}")
                
                # å¦‚æœæœªæ‰¾åˆ°æ¨¡æ¿ï¼Œå†æ£€æŸ¥ç« èŠ‚å¯¹è±¡ä¸­æ˜¯å¦æœ‰MP4é“¾æ¥
                if not mp4_template:
                    for chapter in chapter_list[:5]:  # åªæ£€æŸ¥å‰5ä¸ªç« èŠ‚ä»¥æé«˜æ•ˆç‡
                        if "chapterVideoVo" in chapter and chapter["chapterVideoVo"]:
                            chapter_video = chapter["chapterVideoVo"]
                            mp4_url = chapter_video.get("mp4", "") or chapter_video.get("mp4720p", "") or chapter_video.get("vodMp4Url", "")
                            if mp4_url and ".mp4" in mp4_url:
                                mp4_template = mp4_url
                                first_mp4_chapter_id = chapter.get("chapterId", "")
                                print(f"ä»chapterVideoVoæ‰¾åˆ°MP4é“¾æ¥æ¨¡æ¿: {mp4_template}")
                                print(f"æ¨¡æ¿å¯¹åº”çš„ç« èŠ‚ID: {first_mp4_chapter_id}")
                                break
                
                # éå†æ‰€æœ‰ç« èŠ‚å¤„ç†æ’­æ”¾ä¿¡æ¯
                for chapter in chapter_list:
                    chapter_id = chapter.get("chapterId", "")
                    chapter_name = chapter.get("chapterName", "")
                    
                    # 1. å¦‚æœç« èŠ‚è‡ªèº«æœ‰MP4é“¾æ¥ï¼Œç›´æ¥ä½¿ç”¨
                    if "chapterVideoVo" in chapter and chapter["chapterVideoVo"]:
                        chapter_video = chapter["chapterVideoVo"]
                        mp4_url = chapter_video.get("mp4", "") or chapter_video.get("mp4720p", "") or chapter_video.get("vodMp4Url", "")
                        if mp4_url and ".mp4" in mp4_url:
                            episodes.append(f"{chapter_name}${mp4_url}")
                            continue
                    
                    # 2. å¦‚æœæœ‰MP4æ¨¡æ¿ï¼Œå°è¯•æ›¿æ¢ç« èŠ‚IDæ„å»ºMP4é“¾æ¥
                    if mp4_template and first_mp4_chapter_id and chapter_id:
                        # æ›¿æ¢æ¨¡æ¿ä¸­çš„ç« èŠ‚IDéƒ¨åˆ†
                        if first_mp4_chapter_id in mp4_template:
                            new_mp4_url = mp4_template.replace(first_mp4_chapter_id, chapter_id)
                            episodes.append(f"{chapter_name}${new_mp4_url}")
                            continue
                    
                    # 3. å¦‚æœä¸Šè¿°æ–¹æ³•éƒ½ä¸å¯è¡Œï¼Œå›é€€åˆ°ä½¿ç”¨chapter_idæ„å»ºä¸­é—´URL
                    if chapter_id and chapter_name:
                        url = f"{vod_id}${chapter_id}${chapter_name}"
                        episodes.append(f"{chapter_name}${url}")
            
            if not episodes and vod_id:
                # å°è¯•æ„é€ é»˜è®¤çš„é›†æ•°
                total_chapters = int(book_info.get("totalChapterNum", "0"))
                if total_chapters > 0:
                    print(f"å°è¯•æ„é€  {total_chapters} ä¸ªé»˜è®¤é›†æ•°")
                    
                    # å¦‚æœçŸ¥é“ç« èŠ‚IDçš„æ¨¡å¼ï¼Œå¯ä»¥æ„é€ 
                    if chapter_id and episode_id:
                        for i in range(1, total_chapters + 1):
                            chapter_name = f"ç¬¬{i}é›†"
                            url = f"{vod_id}${chapter_id}${chapter_name}"
                            episodes.append(f"{chapter_name}${url}")
                    else:
                        # ä½¿ç”¨æ™®é€šçš„æ„é€ æ–¹å¼
                        for i in range(1, total_chapters + 1):
                            chapter_name = f"ç¬¬{i}é›†"
                            url = f"{vod_id}${chapter_name}"
                            episodes.append(f"{chapter_name}${url}")
            
            if episodes:
                play_url_list.append("#".join(episodes))
                vod['vod_play_from'] = 'ğŸŒºé£è¨€é”‹è¯­88ğŸŒºæ²³é©¬å‰§åœº'
                vod['vod_play_url'] = '$$$'.join(play_url_list)
            
            result = {
                'list': [vod]
            }
            return result
        except Exception as e:
            print(f"è§£æè¯¦æƒ…é¡µå¤±è´¥: {str(e)}")
            print(traceback.format_exc())
            return {}

    def playerContent(self, flag, id, vipFlags):
        result = {}
        print(f"è°ƒç”¨playerContent: flag={flag}, id={id}")
        
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0",
            "Referer": self.siteUrl,
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8",
            "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8"
        }
        
        # è§£æidå‚æ•°
        parts = id.split('$')
        drama_id = None
        chapter_id = None
        
        if len(parts) >= 2:
            drama_id = parts[0]
            chapter_id = parts[1]
            chapter_name = parts[2] if len(parts) > 2 else "ç¬¬ä¸€é›†"
            print(f"è§£æå‚æ•°: drama_id={drama_id}, chapter_id={chapter_id}")
        else:
            # å¤„ç†æ—§æ•°æ®æ ¼å¼
            print(f"ä½¿ç”¨åŸå§‹URLæ ¼å¼: {id}")
            result["parse"] = 0
            result["url"] = id
            result["header"] = json.dumps(headers)
            return result
        
        # ç›´æ¥æ£€æŸ¥chapter_idæ˜¯å¦åŒ…å«httpï¼ˆå¯èƒ½å·²ç»æ˜¯è§†é¢‘é“¾æ¥ï¼‰
        if 'http' in chapter_id and '.mp4' in chapter_id:
            print(f"å·²ç»æ˜¯MP4é“¾æ¥: {chapter_id}")
            result["parse"] = 0
            result["url"] = chapter_id
            result["header"] = json.dumps(headers)
            return result
        
        # æ„å»ºepisodeé¡µé¢URL
        drama_id_clean = drama_id.replace('/drama/', '')
        episode_url = f"{self.siteUrl}/episode/{drama_id_clean}/{chapter_id}"
        print(f"è¯·æ±‚episodeé¡µé¢: {episode_url}")
        
        try:
            rsp = self.fetch(episode_url, headers=headers)
            if not rsp or rsp.status_code != 200:
                print(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {getattr(rsp, 'status_code', 'N/A')}")
                result["parse"] = 0
                result["url"] = id
                result["header"] = json.dumps(headers)
                return result
            
            html = rsp.text
            print(f"è·å–é¡µé¢å¤§å°: {len(html)} å­—èŠ‚")
            
            # å°è¯•ä»NEXT_DATAæå–è§†é¢‘é“¾æ¥
            mp4_url = None
            
            # æ–¹æ³•1: ä»NEXT_DATAæå–
            next_data_match = re.search(r'<script id="__NEXT_DATA__" type="application/json">(.*?)</script>', html, re.DOTALL)
            if next_data_match:
                try:
                    print("æ‰¾åˆ°NEXT_DATA")
                    next_data = json.loads(next_data_match.group(1))
                    page_props = next_data.get("props", {}).get("pageProps", {})
                    
                    # ä»chapterListä¸­æŸ¥æ‰¾å½“å‰ç« èŠ‚
                    chapter_list = page_props.get("chapterList", [])
                    print(f"æ‰¾åˆ°ç« èŠ‚åˆ—è¡¨ï¼Œé•¿åº¦: {len(chapter_list)}")
                    
                    for chapter in chapter_list:
                        if chapter.get("chapterId") == chapter_id:
                            print(f"æ‰¾åˆ°åŒ¹é…çš„ç« èŠ‚: {chapter.get('chapterName')}")
                            chapter_video = chapter.get("chapterVideoVo", {})
                            mp4_url = chapter_video.get("mp4", "") or chapter_video.get("mp4720p", "") or chapter_video.get("vodMp4Url", "")
                            if mp4_url:
                                print(f"ä»chapterListæ‰¾åˆ°MP4é“¾æ¥: {mp4_url}")
                                break
                    
                    # å¦‚æœæœªæ‰¾åˆ°ï¼Œå°è¯•ä»å½“å‰ç« èŠ‚è·å–
                    if not mp4_url:
                        current_chapter = page_props.get("chapterInfo", {})
                        if current_chapter:
                            print("æ‰¾åˆ°å½“å‰ç« èŠ‚ä¿¡æ¯")
                            chapter_video = current_chapter.get("chapterVideoVo", {})
                            mp4_url = chapter_video.get("mp4", "") or chapter_video.get("mp4720p", "") or chapter_video.get("vodMp4Url", "")
                            if mp4_url:
                                print(f"ä»chapterInfoæ‰¾åˆ°MP4é“¾æ¥: {mp4_url}")
                except Exception as e:
                    print(f"è§£æNEXT_DATAå¤±è´¥: {str(e)}")
                    print(traceback.format_exc())
            
            # æ–¹æ³•2: ç›´æ¥ä»HTMLä¸­æå–MP4é“¾æ¥
            if not mp4_url:
                mp4_pattern = r'(https?://[^"\']+\.mp4)'
                mp4_matches = re.findall(mp4_pattern, html)
                if mp4_matches:
                    # æŸ¥æ‰¾å«æœ‰chapter_idçš„é“¾æ¥
                    matched_mp4 = False
                    for url in mp4_matches:
                        if chapter_id in url:
                            mp4_url = url
                            matched_mp4 = True
                            print(f"ä»HTMLç›´æ¥æå–ç« èŠ‚MP4é“¾æ¥: {mp4_url}")
                            break
                    
                    # å¦‚æœæ²¡æ‰¾åˆ°åŒ…å«chapter_idçš„é“¾æ¥ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ª
                    if not matched_mp4 and mp4_matches:
                        mp4_url = mp4_matches[0]
                        print(f"ä»HTMLç›´æ¥æå–MP4é“¾æ¥: {mp4_url}")
            
            if mp4_url and ".mp4" in mp4_url:
                print(f"æœ€ç»ˆæ‰¾åˆ°çš„MP4é“¾æ¥: {mp4_url}")
                result["parse"] = 0
                result["url"] = mp4_url
                result["header"] = json.dumps(headers)
                return result
            else:
                print(f"æœªæ‰¾åˆ°æœ‰æ•ˆçš„MP4é“¾æ¥ï¼Œå°è¯•å†æ¬¡è§£æé¡µé¢å†…å®¹")
                # å†å°è¯•ä¸€æ¬¡ä»HTMLä¸­å¹¿æ³›æœç´¢æ‰€æœ‰å¯èƒ½çš„MP4é“¾æ¥
                all_mp4_pattern = r'(https?://[^"\']+\.mp4)'
                all_mp4_matches = re.findall(all_mp4_pattern, html)
                if all_mp4_matches:
                    mp4_url = all_mp4_matches[0]
                    print(f"ä»HTMLå¹¿æ³›æœç´¢æ‰¾åˆ°MP4é“¾æ¥: {mp4_url}")
                    result["parse"] = 0
                    result["url"] = mp4_url
                    result["header"] = json.dumps(headers)
                    return result
                
                print(f"æœªæ‰¾åˆ°è§†é¢‘é“¾æ¥ï¼Œè¿”å›åŸepisode URL: {episode_url}")
                result["parse"] = 0
                result["url"] = episode_url
                result["header"] = json.dumps(headers)
                return result
        except Exception as e:
            print(f"è¯·æ±‚æˆ–è§£æå¤±è´¥: {str(e)}")
            print(traceback.format_exc())
            result["parse"] = 0
            result["url"] = id
            result["header"] = json.dumps(headers)
            return result
    
    def localProxy(self, param):
        # æœ¬åœ°ä»£ç†å¤„ç†ï¼Œæ­¤å¤„ç®€å•è¿”å›ä¼ å…¥çš„å‚æ•°
        return [200, "video/MP2T", {}, param]

    def destroy(self):
        # èµ„æºå›æ”¶
        pass 