import json
import re
import sys
import hashlib
import time
from base64 import b64decode, b64encode
from urllib.parse import urlparse, urljoin, urlencode, quote

import requests
from Crypto.Cipher import AES
from Crypto.Util.Padding import unpad
from pyquery import PyQuery as pq

sys.path.append('..')
from base.spider import Spider as BaseSpider

# å›¾ç‰‡ç¼“å­˜ï¼Œé¿å…é‡å¤è§£å¯†
img_cache = {}

class Spider(BaseSpider):

    def init(self, extend=""):
        """åˆå§‹åŒ–ï¼Œæ”¯æŒ extend='{"host":"https://example.com", "proxies":{...}}'"""
        try:
            cfg = json.loads(extend) if isinstance(extend, str) else extend or {}
            self.proxies = cfg.get('proxies', {})
            self.host = (cfg.get('host', '') or '').strip()
            if not self.host:
                self.host = self.get_working_host()
        except:
            self.proxies = {}
            self.host = self.get_working_host()
        
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9',
            'Connection': 'keep-alive',
            'Cache-Control': 'no-cache',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-User': '?1',
            'Upgrade-Insecure-Requests': '1'
        }
        self.headers.update({'Origin': self.host, 'Referer': f"{self.host}/"})
        print(f"[Spider] ä½¿ç”¨ç«™ç‚¹: {self.host}")

    def getName(self):
        return "ğŸŒˆ é€šç”¨è§†é¢‘è§£æå™¨|Proå¢å¼ºç‰ˆ"

    def isVideoFormat(self, url):
        return any(ext in (url or '').lower() for ext in ['.m3u8', '.mp4', '.ts', '.flv', '.mkv', '.avi', '.webm'])

    def manualVideoCheck(self):
        return False

    def destroy(self):
        global img_cache
        img_cache.clear()

    def get_working_host(self):
        """å°è¯•å¤šä¸ªhostï¼Œæ‰¾åˆ°å¯ç”¨çš„"""
        dynamic_urls = [
            'https://wanwuu.com/'
        ]
        for url in dynamic_urls:
            try:
                response = requests.get(url, headers=self.headers, proxies=self.proxies, timeout=3)
                if response.status_code == 200:
                    print(f"[Spider] æ£€æµ‹åˆ°å¯ç”¨host: {url}")
                    return url.rstrip('/')
            except Exception as e:
                continue
        return dynamic_urls[0].rstrip('/') if dynamic_urls else 'https://jszyapi.com'

    def homeContent(self, filter):
        """é¦–é¡µï¼šåŠ¨æ€åˆ†ç±» + è§†é¢‘åˆ—è¡¨ + filters"""
        try:
            response = requests.get(self.host, headers=self.headers, proxies=self.proxies, timeout=10)
            if response.status_code != 200:
                return {'class': [], 'filters': {}, 'list': []}
            
            response.encoding = response.apparent_encoding
            data = self.getpq(response.text)
            
            classes = []
            # å¤šé€‰æ‹©å™¨ï¼šå¯¼èˆªé“¾æ¥
            nav_items = data('nav a, .menu a, .nav a, #header a, .header a, ul.navbar-nav a, .category-list a, .scroll-content a, .module-menu a, .module-tab-item')
            seen_hrefs = set()
            bad_words = ['ç™»å½•', 'æ³¨å†Œ', 'æœç´¢', 'é¦–é¡µ', 'Home', 'Login', 'Search', 'è”ç³»', 'å…³äº', 'ç•™è¨€', 'RSS', 'æ¨ç‰¹', 'TG', 'Qç¾¤', 'åˆä½œ', 'å…¬å‘Š', 'APP', 'ä¸‹è½½']
            
            for k in nav_items.items():
                href = (k.attr('href') or '').strip()
                name = k.text().strip()
                if not href or href in ['#', '/', ''] or 'javascript' in href:
                    continue
                if not name or len(name) < 2 or len(name) > 12:
                    continue
                if any(bw in name for bw in bad_words):
                    continue
                if href in seen_hrefs:
                    continue
                
                # è§„èŒƒåŒ–href
                if not href.startswith('http'):
                    href = urljoin(self.host, href)
                
                classes.append({'type_name': name, 'type_id': href})
                seen_hrefs.add(href)
                if len(classes) >= 25:
                    break
            
            if not classes:
                classes = [
                    {'type_name': 'æœ€æ–°', 'type_id': '/latest/'},
                    {'type_name': 'çƒ­é—¨', 'type_id': '/hot/'},
                    {'type_name': 'æ¨è', 'type_id': '/recommend/'}
                ]
            
            # è§†é¢‘åˆ—è¡¨
            videos = self.getlist(data, '#content article, #main article, .posts article, .container .row article, article, .video-list .video-item, .module-poster-item, .avdata-outer, .search-result, .card')
            
            # filters
            filters = {
                'class': [{'n': 'å…¨éƒ¨', 'v': ''}, {'n': 'é«˜æ¸…', 'v': 'HD'}, {'n': '4K', 'v': '4K'}],
                'area': [{'n': 'å…¨éƒ¨', 'v': ''}, {'n': 'æ—¥æœ¬', 'v': 'jp'}, {'n': 'æ¬§ç¾', 'v': 'us'}, {'n': 'å›½äº§', 'v': 'cn'}],
                'year': [{'n': 'å…¨éƒ¨', 'v': ''}, {'n': '2024', 'v': '2024'}, {'n': '2023', 'v': '2023'}, {'n': '2022', 'v': '2022'}],
                'lang': [{'n': 'å…¨éƒ¨', 'v': ''}, {'n': 'ä¸­æ–‡', 'v': 'zh'}, {'n': 'æ—¥è¯­', 'v': 'jp'}, {'n': 'è‹±æ–‡', 'v': 'en'}]
            }
            
            return {'class': classes, 'filters': filters, 'list': videos}
        except Exception as e:
            print(f"[homeContent] Error: {e}")
            return {'class': [], 'filters': {}, 'list': []}

    def homeVideoContent(self):
        """é¦–é¡µè§†é¢‘å†…å®¹ (å¤ç”¨homeContent)"""
        res = self.homeContent(None)
        return {'list': res.get('list', [])}

    def categoryContent(self, tid, pg, filter, extend):
        """åˆ†ç±»å†…å®¹"""
        try:
            if '@folder' in tid:
                v = self.getfod(tid.replace('@folder', ''))
                return {'list': v, 'page': 1, 'pagecount': 1, 'limit': 90, 'total': len(v)}
            
            pg = int(pg) if pg else 1
            url = tid if tid.startswith('http') else f"{self.host}{tid if tid.startswith('/') else '/' + tid}"
            url = url.rstrip('/')
            
            # æ„é€ åˆ†é¡µURL
            real_url = f"{url}/" if pg == 1 else f"{url}/{pg}/"
            if '?page=' in url or '?pg=' in url:
                real_url = url.replace('{pg}', str(pg))
            
            # extendå‚æ•°æ·»åŠ filter
            if isinstance(extend, dict):
                params = []
                for key in ['class', 'area', 'year', 'lang', 'letter', 'by']:
                    if extend.get(key):
                        params.append(f"{key}={quote(str(extend[key]))}")
                if params:
                    sep = '&' if '?' in real_url else '?'
                    real_url = real_url + sep + '&'.join(params)
            
            print(f"[categoryContent] è¯·æ±‚URL: {real_url}")
            response = requests.get(real_url, headers=self.headers, proxies=self.proxies, timeout=10)
            if response.status_code != 200:
                return {'list': [], 'page': pg, 'pagecount': 9999, 'limit': 90, 'total': 0}
            
            response.encoding = response.apparent_encoding
            data = self.getpq(response.text)
            
            # ã€å…³é”®ä¿®å¤ã€‘åˆ†ç±»é¡µé¢ç”¨æ›´å…¨é¢çš„é€‰æ‹©å™¨
            videos = self.getlist(
                data, 
                '.module-item, .module-poster-item, .video-item, article, .card, li.vodlist_item, .stui-vodlist__box, a.module-item-pic, .myui-vodlist__box',
                tid
            )
            
            print(f"[categoryContent] æå–åˆ° {len(videos)} ä¸ªè§†é¢‘")
            return {'list': videos, 'page': pg, 'pagecount': 9999, 'limit': 90, 'total': 999999}
        except Exception as e:
            print(f"[categoryContent] Error: {e}")
            import traceback
            traceback.print_exc()
            return {'list': [], 'page': pg, 'pagecount': 9999, 'limit': 90, 'total': 0}

    def detailContent(self, ids):
        """è¯¦æƒ…é¡µï¼šæå–è§†é¢‘æºï¼ˆå¢å¼ºç‰ˆï¼‰"""
        try:
            url = ids[0] if ids[0].startswith('http') else f"{self.host}{ids[0]}"
            response = requests.get(url, headers=self.headers, proxies=self.proxies, timeout=10)
            response.encoding = response.apparent_encoding
            html_text = response.text
            data = self.getpq(html_text)
            
            plist = []
            unique_urls = set()

            def add_play_url(name, u):
                if not u or u in unique_urls:
                    return
                if not u.startswith('http'):
                    u = urljoin(self.host, u)
                unique_urls.add(u)
                plist.append(f"{name}${u}")

            # 1. Script ä¸­çš„ m3u8/mp4 (ä¼˜å…ˆçº§æœ€é«˜)
            scripts = data('script')
            for s in scripts.items():
                txt = s.text()
                if 'url' in txt and ('.m3u8' in txt or '.mp4' in txt):
                    urls = re.findall(r'["\']+(http[^"\']+\.(?:m3u8|mp4)[^\'"]*)["\']', txt)
                    for u in urls:
                        add_play_url("è„šæœ¬æº", u)
                        break

            # 2. DPlayer é…ç½®
            if data('.dplayer'):
                for c, k in enumerate(data('.dplayer').items(), start=1):
                    config_attr = k.attr('data-config')
                    if config_attr:
                        try:
                            config = json.loads(config_attr)
                            video_url = config.get('video', {}).get('url', '')
                            if video_url:
                                add_play_url(f"DPlayer{c}", video_url)
                        except:
                            pass

            # 3. Video æ ‡ç­¾ (HTML5)
            for v in data('video').items():
                src = v.attr('src')
                if src:
                    add_play_url("HTML5è§†é¢‘", src)
                for src_tag in v('source').items():
                    add_play_url("HTML5æº", src_tag.attr('src'))

            # 4. Iframe å—…æ¢
            for iframe in data('iframe').items():
                src = iframe.attr('src') or iframe.attr('data-src')
                if src and any(x in src for x in ['.m3u8', '.mp4', 'upload', 'cloud', 'player', 'embed']):
                    if not any(x in src for x in ['google', 'facebook', 'disqus']):
                        add_play_url("Iframeæº", src)

            # 5. é€šç”¨å˜é‡/JSON æ­£åˆ™ (æ ¸å¿ƒå¢å¼º)
            common_patterns = [
                r'var\s+main\s*=\s*["\']([^"\']+)["\']',
                r'url\s*:\s*["\']([^"\']+\.(?:m3u8|mp4))["\']',
                r'vurl\s*=\s*["\']([^"\']+)["\']',
                r'vid\s*:\s*["\']([^"\']+\.(?:m3u8|mp4))["\']',
                r'"url"\s*:\s*"([^"]+)"',
                r'video_url\s*=\s*[\'"]([^\'"]+)[\'"]',
                r'var\s+videoUrl\s*=\s*["\']([^"\']+)["\']',
                r'playurl\s*=\s*["\']([^"\']+)["\']',
                r'"playUrl"\s*:\s*"([^"]+)"',
                r'src="([^"]*\.(?:m3u8|mp4)[^"]*)"',
                r'data-src="([^"]*\.(?:m3u8|mp4)[^"]*)"',
                r'mp4Url\s*=\s*["\']([^"\']+)["\']',
                r'm3u8Url\s*=\s*["\']([^"\']+)["\']',
            ]
            for pat in common_patterns:
                matches = re.finditer(pat, html_text, re.IGNORECASE)
                for match in matches:
                    u = match.group(1)
                    if any(ext in u for ext in ['.m3u8', '.mp4', '.flv', '.m4v']):
                        add_play_url("æ­£åˆ™æº", u)

            # 6. Script JSON embed (ThePorn/porn87é£æ ¼)
            try:
                json_matches = re.findall(r'<script[^>]*type="text/javascript"[^>]*>(.*?)</script>', html_text, re.DOTALL)
                for json_str in json_matches:
                    try:
                        obj = json.loads(json_str)
                        if isinstance(obj, dict):
                            for k, v in obj.items():
                                if isinstance(v, str) and ('.m3u8' in v or '.mp4' in v):
                                    add_play_url(f"JSON-{k}", v)
                    except:
                        pass
            except:
                pass

            # 7. å…œåº•ï¼šæ–‡æœ¬é“¾æ¥
            if not plist:
                content_area = data('.post-content, article, .content, .video-info, .module-info-introduction')
                for i, link in enumerate(content_area('a').items(), start=1):
                    link_text = link.text().strip()
                    link_href = link.attr('href')
                    if link_href and any(kw in link_text for kw in ['ç‚¹å‡»è§‚çœ‹', 'è§‚çœ‹', 'æ’­æ”¾', 'è§†é¢‘', 'ç¬¬ä¸€å¼¹', 'çº¿è·¯', 'Play', 'æ’­æ”¾å™¨']):
                        ep_name = link_text.replace('ç‚¹å‡»è§‚çœ‹ï¼š', '').replace('ç‚¹å‡»è§‚çœ‹', '').strip()
                        if not ep_name:
                            ep_name = f"çº¿è·¯{i}"
                        add_play_url(ep_name, link_href)

            play_url = '#'.join(plist) if plist else f"æ— è§†é¢‘æºï¼Œè¯·å°è¯•ç½‘é¡µæ’­æ”¾${url}"
            
            # æ ‡é¢˜
            vod_title = data('h1').text().strip()
            if not vod_title:
                vod_title = data('.post-title, .module-info-heading, .video-title').text().strip()
            if not vod_title:
                vod_title = data('title').text().split('|')[0].strip()
            
            # æè¿°
            vod_content = data('.post-content, article, .module-info-introduction-content, .video-desc').text().strip()
            
            return {'list': [{'vod_play_from': 'é€šç”¨è§£æ', 'vod_play_url': play_url, 'vod_content': vod_content or vod_title}]}
        except Exception as e:
            print(f"[detailContent] Error: {e}")
            import traceback
            traceback.print_exc()
            return {'list': [{'vod_play_from': 'é€šç”¨è§£æ', 'vod_play_url': 'è·å–å¤±è´¥'}]}

    def searchContent(self, key, quick, pg="1"):
        """æœç´¢"""
        try:
            pg = int(pg) if pg else 1
            url = f"{self.host}/?s={quote(key)}"
            response = requests.get(url, headers=self.headers, proxies=self.proxies, timeout=10)
            response.encoding = response.apparent_encoding
            data = self.getpq(response.text)
            videos = self.getlist(data, 'article, .search-result, .post, .video-item, .module-poster-item, .avdata-outer, .card, .module-item')
            return {'list': videos, 'page': pg, 'pagecount': 9999}
        except Exception as e:
            print(f"[searchContent] Error: {e}")
            return {'list': [], 'page': pg, 'pagecount': 9999}

    def playerContent(self, flag, id, vipFlags):
        """æ’­æ”¾å™¨"""
        if 'html' in id or 'php' in id or 'embed' in id or 'player' in id:
            parse = 1  # éœ€è¦è§£æ
        elif self.isVideoFormat(id):
            parse = 0  # ç›´æ¥æ’­æ”¾
        else:
            parse = 1
        
        url = self.proxy(id) if '.m3u8' in id else id
        return {'parse': parse, 'url': url, 'header': self.headers}

    def localProxy(self, param):
        """æœ¬åœ°ä»£ç†ï¼šå¤„ç†m3u8/ts/å›¾ç‰‡è§£å¯†"""
        try:
            type_ = param.get('type')
            url = param.get('url')
            
            if type_ == 'cache':
                key = param.get('key')
                if content := img_cache.get(key):
                    return [200, 'image/jpeg', content]
                return [404, 'text/plain', b'Expired']
            
            elif type_ == 'img':
                real_url = self.d64(url) if not url.startswith('http') else url
                res = requests.get(real_url, headers=self.headers, proxies=self.proxies, timeout=10)
                content = self.aesimg(res.content)
                return [200, 'image/jpeg', content]
            
            elif type_ == 'm3u8':
                return self.m3Proxy(url)
            
            else:  # ts
                return self.tsProxy(url)
        except Exception as e:
            print(f"[localProxy] Error: {e}")
            return [404, 'text/plain', b'']

    def proxy(self, data, type='m3u8'):
        """ç”Ÿæˆä»£ç†URL"""
        if data and self.proxies:
            return f"{self.getProxyUrl()}&url={self.e64(data)}&type={type}"
        return data

    def m3Proxy(self, url):
        """m3u8ä»£ç†"""
        try:
            url = self.d64(url)
            res = requests.get(url, headers=self.headers, proxies=self.proxies, timeout=10)
            res.encoding = res.apparent_encoding
            data = res.text
            base = res.url.rsplit('/', 1)[0]
            lines = []
            
            for line in data.split('\n'):
                if '#EXT' not in line and line.strip():
                    if not line.startswith('http'):
                        if line.startswith('/'):
                            host_base = '/'.join(res.url.split('/')[:3])
                            line = f"{host_base}{line}"
                        else:
                            line = f"{base}/{line}"
                    lines.append(self.proxy(line, 'ts'))
                else:
                    lines.append(line)
            
            return [200, "application/vnd.apple.mpegurl", '\n'.join(lines)]
        except Exception as e:
            print(f"[m3Proxy] Error: {e}")
            return [404, 'text/plain', b'']

    def tsProxy(self, url):
        """tsä»£ç†"""
        try:
            content = requests.get(self.d64(url), headers=self.headers, proxies=self.proxies, timeout=10).content
            return [200, 'video/mp2t', content]
        except:
            return [404, 'text/plain', b'']

    def e64(self, text):
        """base64ç¼–ç """
        return b64encode(str(text).encode()).decode()

    def d64(self, text):
        """base64è§£ç """
        return b64decode(str(text).encode()).decode()

    def aesimg(self, data):
        """AESè§£å¯†å›¾ç‰‡"""
        if len(data) < 16:
            return data
        
        # å¤šå¯†é’¥å°è¯• (ä»æˆå“æå–)
        keys = [
            (b'f5d965df75336270', b'97b60394abc2fbe1'),
            (b'75336270f5d965df', b'abc2fbe197b60394'),
        ]
        
        for k, v in keys:
            try:
                dec = unpad(AES.new(k, AES.MODE_CBC, v).decrypt(data), 16)
                if dec.startswith(b'\xff\xd8') or dec.startswith(b'\x89PNG') or dec.startswith(b'GIF8'):
                    return dec
            except:
                pass
            try:
                dec = unpad(AES.new(k, AES.MODE_ECB).decrypt(data), 16)
                if dec.startswith(b'\xff\xd8'):
                    return dec
            except:
                pass
        
        return data

    def getlist(self, data_pq, selector, tid=''):
        """è§£æè§†é¢‘åˆ—è¡¨"""
        videos = []
        is_folder = '/mrdg' in (tid or '')
        
        items = data_pq(selector)
        if len(items) == 0:
            items = data_pq('a:has(img)')
        
        print(f"[getlist] æ‰¾åˆ° {len(items)} ä¸ªå€™é€‰é¡¹")
        
        seen_ids = set()
        ad_keywords = ['å¨±ä¹', 'æ£‹ç‰Œ', 'æ¾³é—¨', 'è‘¡äº¬', 'å¤ªé˜³åŸ', 'å½©ç¥¨', 'AV', 'ç›´æ’­', 'å……å€¼', 'ä¸‹è½½', 'å›å®¶']

        for k in items.items():
            # ã€å…³é”®ä¿®å¤ã€‘æ›´çµæ´»çš„é“¾æ¥æå–
            if k.is_('a'):
                a = k
                container = k.parent()
            else:
                # ä¼˜å…ˆæŸ¥æ‰¾å¸¦hrefçš„aæ ‡ç­¾
                a = k('a[href]').eq(0)
                if not a or not a.attr('href'):
                    a = k('a').eq(0)
                container = k

            href = a.attr('href')
            if not href:
                continue
            
            if any(x in href for x in ['/category/', '/tag/', '/feed/', '/page/', '/author/', 'gitlub']):
                continue
            if href in ['/', '#']:
                continue

            # ã€ä¼˜åŒ–ã€‘æ ‡é¢˜æå–
            title = container.find('h2, h3, h4, .title, .video-title, .module-poster-item-title, .module-item-title').text()
            if not title:
                title = a.attr('title') or a.attr('data-title')
            if not title:
                title = a.find('img').attr('alt')
            if not title:
                title = container.find('.video-name, .vodlist_title').text()
            if not title:
                title = a.text()
            
            if not title or len(title.strip()) < 2:
                continue
            if any(ad in title for ad in ad_keywords):
                continue

            card_html = k.outer_html() if hasattr(k, 'outer_html') else str(k)
            script_text = k('script').text()
            img = self.getimg(script_text, k, card_html)
            
            if not img:
                continue
            if '.gif' in img.lower():
                continue
            
            if href in seen_ids:
                continue
            
            if not href.startswith('http'):
                href = urljoin(self.host, href)
            
            seen_ids.add(href)
            remark = container.find('time, .date, .meta, .views, .video-duration, .module-item-note, .pic-text').text() or ''

            videos.append({
                'vod_id': f"{href}{'@folder' if is_folder else ''}",
                'vod_name': title.strip(),
                'vod_pic': img,
                'vod_remarks': remark,
                'vod_tag': 'folder' if is_folder else '',
                'style': {"type": "rect", "ratio": 1.33}
            })
        
        return videos

    def getimg(self, text, elem=None, html_content=None):
        """æå–å›¾ç‰‡URL"""
        # 1. var img_url (åƒç“œç½‘ç‰¹è‰²)
        if m := re.search(r'var\s+img_url\s*=\s*[\'"]([^\'"]+)[\'"]', text or ''):
            return self._proc_url(m.group(1))
        
        # 2. loadBannerDirect
        if m := re.search(r"loadBannerDirect\('([^']+)'", text or ''):
            return self._proc_url(m.group(1))
        
        if html_content is None and elem is not None:
            html_content = elem.outer_html() if hasattr(elem, 'outer_html') else str(elem)
        if not html_content:
            return ''

        html_content = html_content.replace('&quot;', '"').replace('&apos;', "'").replace('&amp;', '&')

        # 3. data-src / data-original
        if m := re.search(r'data-src\s*=\s*["\']([^"\']+)["\']', html_content, re.I):
            return self._proc_url(m.group(1))
        if m := re.search(r'data-original\s*=\s*["\']([^"\']+)["\']', html_content, re.I):
            return self._proc_url(m.group(1))

        # 4. httpé“¾æ¥
        if m := re.search(r'(https?://[^"\'\s)]+\.(?:jpg|png|jpeg|webp|gif))', html_content, re.I):
            return self._proc_url(m.group(1))

        # 5. url()
        if 'url(' in html_content:
            m = re.search(r'url\s*\(\s*[\'"]?([^\"\'\)]+)[\'"]?\s*\)', html_content, re.I)
            if m:
                return self._proc_url(m.group(1))
        
        # 6. srcå±æ€§
        if m := re.search(r'src\s*=\s*["\']([^"\']+\.(?:jpg|png|jpeg|webp|gif))["\']', html_content, re.I):
            return self._proc_url(m.group(1))
        
        return ''

    def _proc_url(self, url):
        """å¤„ç†URLï¼šè½¬ä¹‰ã€ä»£ç†ã€AES"""
        if not url:
            return ''
        url = url.strip('\'" ')
        
        if url.startswith('data:'):
            try:
                _, b64_str = url.split(',', 1)
                raw = b64decode(b64_str)
                if not (raw.startswith(b'\xff\xd8') or raw.startswith(b'\x89PNG') or raw.startswith(b'GIF8')):
                    raw = self.aesimg(raw)
                key = hashlib.md5(raw).hexdigest()
                img_cache[key] = raw
                return f"{self.getProxyUrl()}&type=cache&key={key}"
            except:
                return ""
        
        if not url.startswith('http'):
            url = urljoin(self.host, url)
        
        # æ‰€æœ‰å›¾ç‰‡èµ°ä»£ç†è§£å¯†
        return f"{self.getProxyUrl()}&url={self.e64(url)}&type=img"

    def getfod(self, id):
        """æ–‡ä»¶å¤¹å¤„ç†"""
        return []

    def getpq(self, data):
        """è·å–pqå¯¹è±¡"""
        try:
            return pq(data)
        except:
            return pq(data.encode('utf-8'))
